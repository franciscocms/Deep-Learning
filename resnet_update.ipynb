{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_update.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dEZWk9EdANO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBtyW5CCxH7H"
      },
      "source": [
        "def activation_func(activation):\n",
        "    return  nn.ModuleDict([\n",
        "        ['relu', nn.ReLU(inplace=True)],\n",
        "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
        "        ['selu', nn.SELU(inplace=True)],\n",
        "        ['none', nn.Identity()]\n",
        "    ])[activation]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSWgCS_58hav"
      },
      "source": [
        "**Basic Block**\n",
        "\n",
        "First, let's create the **basic block**.\n",
        "As we are implementing ResNet-18-34, the **basic block** module comprises:\n",
        "* **(1)** convolutional + batch_normalization layers\n",
        "* ReLU activation\n",
        "* **(2)** convolutional + batch_normalization layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akfeUO0bdFgZ"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bottleneck_size, downsampling = 1, activation='relu'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.downsampling = downsampling\n",
        "\n",
        "        self.in_channels, self.out_channels = in_channels, out_channels\n",
        "\n",
        "        if in_channels != out_channels:\n",
        "            self.downsampling = 2\n",
        "        \n",
        "        self.bottleneck_size = bottleneck_size\n",
        "        if self.bottleneck_size == 2:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = self.downsampling, padding = 1, bias = False)\n",
        "            self.bn1 = nn.BatchNorm2d(num_features = out_channels)\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "            self.bn2 = nn.BatchNorm2d(num_features = out_channels)\n",
        "            self.activate = activation_func(activation)\n",
        "        \n",
        "        # in_channels and out_channels from the block (first: 64 and 256)\n",
        "        elif self.bottleneck_size == 3:\n",
        "            self.conv1 = nn.Conv2d(in_channels, int(out_channels/4), kernel_size = 1, bias = False)\n",
        "            self.bn1 = nn.BatchNorm2d(num_features = int(out_channels/4))\n",
        "            self.conv2 = nn.Conv2d(int(out_channels/4), int(out_channels/4), kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "            self.bn2 = nn.BatchNorm2d(num_features = int(out_channels/4))\n",
        "            self.conv3 = nn.Conv2d(int(out_channels/4), out_channels, kernel_size = 1, bias = False)\n",
        "            self.bn3 = nn.BatchNorm2d(num_features = out_channels)\n",
        "        \n",
        "        \n",
        "        self.activate = activation_func(activation)\n",
        "  \n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.bottleneck_size == 2:        \n",
        "            out = self.conv1(x)\n",
        "            out = self.bn1(out)\n",
        "            out = self.activate(out)\n",
        "\n",
        "            out = self.conv2(out)\n",
        "            out = self.bn2(out)\n",
        "\n",
        "            return out\n",
        "\n",
        "        elif self.bottleneck_size == 3:\n",
        "            out = self.conv1(x)\n",
        "            out = self.bn1(out)\n",
        "            out = self.activate(out)\n",
        "\n",
        "            out = self.conv2(out)\n",
        "            out = self.bn2(out)\n",
        "            out = self.activate(out)\n",
        "\n",
        "            out = self.conv3(out)\n",
        "            out = self.bn3(out)\n",
        "\n",
        "            return out\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkT7Unuqr7xd"
      },
      "source": [
        "**Residual Block**\n",
        "\n",
        "Here, we create the residual part of the network.\n",
        "\n",
        "The parameter *depth* gives the number of **basic blocks** that should be stacked to form each **residual block**.\n",
        "\n",
        "As in the original paper, \"*we perform downsampling directly by\n",
        "convolutional layers that have a stride of 2*\", and the first *conv* layer of each **residual block** is the one with stride = 2.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPB0JI4NqzCU"
      },
      "source": [
        "\n",
        "\n",
        "<img height=\"200\" src=\"https://miro.medium.com/max/713/1*D0F3UitQ2l5Q0Ak-tjEdJg.png\" srcset=\"https://miro.medium.com/max/345/1*D0F3UitQ2l5Q0Ak-tjEdJg.png 276w, https://miro.medium.com/max/690/1*D0F3UitQ2l5Q0Ak-tjEdJg.png 552w, https://miro.medium.com/max/713/1*D0F3UitQ2l5Q0Ak-tjEdJg.png 570w\" sizes=\"570px\" float = \"center\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtgLp4Bsq_gh"
      },
      "source": [
        "class ResNetResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, depth, bottleneck_size, downsampling = 1, activation='relu'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.bottleneck_size = bottleneck_size\n",
        "        self.downsampling = downsampling\n",
        "        \n",
        "        if self.bottleneck_size == 2:\n",
        "            self.downsampling = 1 if self.in_channels == self.out_channels else 2 \n",
        "        else:\n",
        "            self.downsampling = 1\n",
        "      \n",
        "        self.blocks = nn.ModuleList([\n",
        "            BasicBlock(self.in_channels, self.out_channels, self.bottleneck_size),\n",
        "            *[BasicBlock(self.out_channels, self.out_channels, self.bottleneck_size) for i in range(depth - 1)]\n",
        "        ])\n",
        "\n",
        "        self.shortcuts = nn.ModuleList([\n",
        "            *[nn.Sequential(\n",
        "                nn.Conv2d(self.blocks[i].in_channels, self.blocks[i].out_channels, kernel_size = 1, stride = self.downsampling, bias = False),\n",
        "                nn.BatchNorm2d(self.blocks[i].out_channels)) if self.blocks[i].in_channels != self.blocks[i].out_channels else nn.Identity() for i in range(depth)]\n",
        "        ])\n",
        "\n",
        "        self.activate = activation_func(activation)\n",
        "    \n",
        "    def forward(self, x):\n",
        "          \n",
        "        for i in range(len(self.blocks)):\n",
        "            residual = self.shortcuts[i](x)\n",
        "            x = self.blocks[i](x)\n",
        "            x += residual\n",
        "            x = self.activate(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvY3rY2vAFdH"
      },
      "source": [
        "**ResNet Encoder**\n",
        "\n",
        "Here, we stack the entire network encoder:\n",
        "* the *gate* performs the first block of processing\n",
        "* the sequencial module of **blocks**, where each block is created using *depths* and *block_sizes* parameters, corresponding to the number of **basic blocks** and their channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU3USL314gHw"
      },
      "source": [
        "class ResNetEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, depths, bottleneck_size, block_sizes, activation='relu'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        self.block = ResNetResidualBlock\n",
        "        self.block_sizes = block_sizes\n",
        "        self.n = len(self.block_sizes)\n",
        "\n",
        "        \n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Conv2d(self.in_channels, self.block_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(self.block_sizes[0]),\n",
        "            activation_func(activation),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        if bottleneck_size == 2:\n",
        "            self.blocks = nn.Sequential(\n",
        "                self.block(self.block_sizes[0], self.block_sizes[0], depth = depths[0], bottleneck_size = bottleneck_size),\n",
        "                *[self.block(self.block_sizes[k], self.block_sizes[k + 1], depth = depths[k+1], bottleneck_size = bottleneck_size) for k in range(len(depths) -1)]       \n",
        "            )\n",
        "        elif bottleneck_size == 3:\n",
        "            self.blocks = nn.Sequential(\n",
        "                self.block(self.block_sizes[0], self.block_sizes[0]*4, depth = depths[0], bottleneck_size = bottleneck_size),\n",
        "                *[self.block(self.block_sizes[k]*4, self.block_sizes[k + 1]*4, depth = depths[k+1], bottleneck_size = bottleneck_size) for k in range(len(depths) -1)]       \n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.gate(x)\n",
        "        x = self.blocks(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6hGpsAg2tgz"
      },
      "source": [
        "class ResNetClassifier(nn.Module):\n",
        "    def __init__(self, in_features, n_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Linear(in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0l12SSqHhVI"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, in_channels, n_classes, depths, block_sizes, bottleneck_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = ResNetEncoder(in_channels, depths, bottleneck_size, block_sizes)\n",
        "        self.classifier = ResNetClassifier(self.encoder.blocks[-1].out_channels, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSQGG_GJT7D7"
      },
      "source": [
        "from torchsummary import summary\n",
        "import torchvision.models as models\n",
        "\n",
        "def resnet18(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, depths = [2,2,2,2], block_sizes = [64, 128, 256, 512], bottleneck_size = 2)\n",
        "\n",
        "def resnet34(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, depths = [3,4,6,3], block_sizes = [64, 128, 256, 512], bottleneck_size = 2)\n",
        "\n",
        "def resnet50(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, depths = [3,4,6,3], block_sizes = [64, 128, 256, 512], bottleneck_size = 3)\n",
        "\n",
        "def resnet101(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, depths = [3,4,23,3], block_sizes = [64, 128, 256, 512], bottleneck_size = 3)\n",
        "\n",
        "def resnet152(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, depths = [3,8,36,3], block_sizes = [64, 128, 256, 512], bottleneck_size = 3)\n",
        "\n",
        "# uncomment line below to check if everything works out!\n",
        "\n",
        "#model = resnet18(3, 1000)\n",
        "#model = resnet34(3, 1000)\n",
        "#model = resnet50(3, 1000)\n",
        "#model = resnet101(3, 1000)\n",
        "#model = resnet152(3, 1000)\n",
        "\n",
        "summary(model, (3, 224, 224))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBv5IR4fkWAt"
      },
      "source": [
        "summary(models.resnet152(False), (3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}